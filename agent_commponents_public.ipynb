{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poll Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_core.prompts import PromptTemplate , ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from react_template import get_react_prompt_template\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from langchain.tools.render import render_text_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a .env file to save yout model api keys\n",
    "# Specify the path to your .env file if it's not in the same directory as your script\n",
    "dotenv_path = '.env'\n",
    "\n",
    "# Load the environment variables from your .env file\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "# api_key = abcd1234\n",
    "model = ChatOpenAI(model=\"gpt-4\", api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch data fom BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = bigquery.Client(credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_top_5_content():\n",
    "#     \"\"\"Returns a dataframe of content_id and story_headline for the top 3 stories\"\"\"\n",
    "    \n",
    "#     query = \"\"\"\n",
    "#         \"\"\"\n",
    "    \n",
    "#     query_job = client.query(query)\n",
    "#     results = query_job.result()\n",
    "    \n",
    "#     return results.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_5_content = get_top_5_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_content = [{'content_id': '11399681',\n",
    "  'story_headline': \"10 ways world could spiral into nuke war as summer of Putin victories would mark first steps to WW3, army bosses warn. Scroll down to see The Sun's graphic on how Putin's summer offensive could turn into WW3 in 10 steps\"},\n",
    " {'content_id': '11403108',\n",
    "  'story_headline': 'Alice Stewart suddenly dead at 58 after CNN correspondent & ex-Ted Cruz adviser’s body found outside near her home. Stewart appeared on CNN as recently as Friday night'},\n",
    " {'content_id': '11407921',\n",
    "  'story_headline': 'Watch moment giant meteor travelling at 1,700mph turns night sky blue over Spain and Portugal in rare spectacle. Watch the epic moment in the above video'},\n",
    " {'content_id': '11359687',\n",
    "  'story_headline': 'Everyone sees the rabbit – but you have high IQ and 20/20 vision if you can find the diamond ring in under 15 seconds. Keep reading to challenge yourself with more puzzling brain teasers'},\n",
    " {'content_id': '11409310',\n",
    "  'story_headline': 'Chilling footage shows Iran’s president Ebrahim Raisi in helicopter moments before crash as fog hampers frantic search. The controversial leader is feared dead as search crews struggle to reach the crash site'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert top_content to a dataframe\n",
    "top_5_content = pd.DataFrame(top_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>story_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11399681</td>\n",
       "      <td>10 ways world could spiral into nuke war as su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11403108</td>\n",
       "      <td>Alice Stewart suddenly dead at 58 after CNN co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11407921</td>\n",
       "      <td>Watch moment giant meteor travelling at 1,700m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11359687</td>\n",
       "      <td>Everyone sees the rabbit – but you have high I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11409310</td>\n",
       "      <td>Chilling footage shows Iran’s president Ebrahi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  content_id                                     story_headline\n",
       "0   11399681  10 ways world could spiral into nuke war as su...\n",
       "1   11403108  Alice Stewart suddenly dead at 58 after CNN co...\n",
       "2   11407921  Watch moment giant meteor travelling at 1,700m...\n",
       "3   11359687  Everyone sees the rabbit – but you have high I...\n",
       "4   11409310  Chilling footage shows Iran’s president Ebrahi..."
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content ID: 11399681\n",
      "Story Headline: 10 ways world could spiral into nuke war as summer of Putin victories would mark first steps to WW3, army bosses warn. Scroll down to see The Sun's graphic on how Putin's summer offensive could turn into WW3 in 10 steps\n",
      "\n",
      "\n",
      "Content ID: 11403108\n",
      "Story Headline: Alice Stewart suddenly dead at 58 after CNN correspondent & ex-Ted Cruz adviser’s body found outside near her home. Stewart appeared on CNN as recently as Friday night\n",
      "\n",
      "\n",
      "Content ID: 11407921\n",
      "Story Headline: Watch moment giant meteor travelling at 1,700mph turns night sky blue over Spain and Portugal in rare spectacle. Watch the epic moment in the above video\n",
      "\n",
      "\n",
      "Content ID: 11359687\n",
      "Story Headline: Everyone sees the rabbit – but you have high IQ and 20/20 vision if you can find the diamond ring in under 15 seconds. Keep reading to challenge yourself with more puzzling brain teasers\n",
      "\n",
      "\n",
      "Content ID: 11409310\n",
      "Story Headline: Chilling footage shows Iran’s president Ebrahim Raisi in helicopter moments before crash as fog hampers frantic search. The controversial leader is feared dead as search crews struggle to reach the crash site\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for story in top_5_content.itertuples():\n",
    "    print(f\"Content ID: {story.content_id}\")\n",
    "    print(f\"Story Headline: {story.story_headline}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create functions that use agents to generate content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_headline_appropriate(headline_story):\n",
    "    prompt_template = ChatPromptTemplate.from_template(\"You are an expert on generating meaningful and healthy polls for news articles to increase healthy engagement with readers. Only serious news article needs to be approved. Riddles, games, puzzles and brainteasers are not appropriate. Stricly answer in one word, 'Yes' or 'No' if the given headline story is appropriate for poll generation or not: {headline_story}\")\n",
    "    output_parser = StrOutputParser()\n",
    "    chain = prompt_template | model | output_parser\n",
    "    result = chain.invoke({\"headline_story\": headline_story})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to generate poll questions\n",
    "def generate_poll_question(headline_story):\n",
    "    prompt_template = PromptTemplate.from_template(\"You are a good UK citizen and also a poll generating agent that asks good and sincere poll question to the news article readers based on a story headline. Generate a multiple choice poll question for this story headline: {input}?\")\n",
    "    # execute\n",
    "    output_parser = StrOutputParser()\n",
    "    chain = prompt_template | model | output_parser\n",
    "    result = chain.invoke({\"input\": headline_story})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy to avoid modifying the original dataframe\n",
    "df = top_5_content.copy() \n",
    "\n",
    "# Create a new column 'poll_question'\n",
    "df['poll_question'] = ''\n",
    "\n",
    "# Iterate over the rows of the dataframe\n",
    "for index, row in df.iterrows():\n",
    "    headline_story = row['story_headline']\n",
    "    \n",
    "    # Check if the headline is appropriate\n",
    "    if is_headline_appropriate(headline_story) == 'Yes':\n",
    "        # Generate the poll question\n",
    "        poll_question = generate_poll_question(headline_story)\n",
    "        df.at[index, 'poll_question'] = poll_question\n",
    "    else:\n",
    "        # Leave the 'poll_question' cell empty\n",
    "        df.at[index, 'poll_question'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def append_table_from_dataframe(\n",
    "#     dataframe: pd.DataFrame,\n",
    "#     table_id: str,\n",
    "#     client: bigquery.Client,\n",
    "#     ) -> None:\n",
    "#     job_config = bigquery.LoadJobConfig()\n",
    "#     job_config.create_disposition = \"CREATE_IF_NEEDED\"\n",
    "#     job_config.write_disposition = \"WRITE_APPEND\"\n",
    "#     job = client.load_table_from_dataframe(dataframe, table_id, job_config=job_config)\n",
    "#     job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append_table_from_dataframe(df,\n",
    "#                             table_id = \"project.dataset.agent_generated_polls\", \n",
    "#                             client = client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story Headline: John F. Kennedy’s son ‘cheated on wife Carolyn Bessette-Kennedy 48 hours before’ they died in plane crash, friend claims. JFK Jr's close friend assumed the president's son had a fling with an old flame after a row with his wife\n",
      "Poll Question: Based on the recent claims about John F. Kennedy Jr.'s infidelity just before his tragic death, do you believe that the public's perception of him will be significantly affected? \n",
      "\n",
      "A) Yes, it tarnishes his image completely.\n",
      "B) Yes, but it doesn't change my overall opinion of him.\n",
      "C) No, his personal life doesn't affect my view of him.\n",
      "D) No, I don't believe the claims. \n",
      "E) I am not sure.\n",
      "\n",
      "\n",
      "Story Headline: Everyone can see the ladder but you have 20/20 vision and a high IQ if you can spot the hidden cat in under 4 seconds. Scroll down for some more mind-boggling fun\n",
      "Poll Question: \n",
      "\n",
      "\n",
      "Story Headline: I was forced to sell my home after HOA took $600 from my paycheck every two weeks over weeds – it was my only way out. See how lawmakers hope to crack down on overzealous HOAs\n",
      "Poll Question: Do you believe lawmakers should implement stricter regulations on Homeowners Associations (HOAs) to prevent overcharging homeowners? \n",
      "A) Yes, there should be stricter regulations \n",
      "B) No, HOAs should continue to operate as they are \n",
      "C) I'm not sure \n",
      "D) I don't think this is a widespread problem\n",
      "\n",
      "\n",
      "Story Headline: My neighbor built a driveway on my land – I took the smelliest revenge possible and there’s nothing they can do. Another group of neighbors called upon their city to make a change\n",
      "Poll Question: What would be your reaction if your neighbor built a driveway on your land without permission?\n",
      "A) Confront them directly \n",
      "B) Take a unique revenge like the person in the article \n",
      "C) Call upon your city to enforce property laws \n",
      "D) Ignore it and avoid conflict\n",
      "\n",
      "\n",
      "Story Headline: Everyone can see a burning candle but you have a high IQ and 20/20 vision if you can spot the illusive cat in 6 seconds. Scroll down for some more mind-boggling fun\n",
      "Poll Question: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print story  headline and poll question for each story in df\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Story Headline: {row['story_headline']}\")\n",
    "    print(f\"Poll Question: {row['poll_question']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pydantic Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure.\n",
    "class Poll(BaseModel):\n",
    "    poll_question: str = Field(description=\"Poll question for the news article story\")\n",
    "    option_1: str = Field(description=\"Option 1 for the poll question\")\n",
    "    option_2: str = Field(description=\"Option 2 for the poll question\")\n",
    "    option_3: str = Field(description=\"Option 3 for the poll question\")\n",
    "    option_4: str = Field(description=\"Option 4 for the poll question\")\n",
    "    option_5: str = Field(description=\"Option 5 for the poll question\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a parser + inject instructions into the prompt template.\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=Poll)\n",
    "\n",
    "format_instructions = pydantic_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"poll_question\": {\"description\": \"Poll question for the news article story\", \"title\": \"Poll Question\", \"type\": \"string\"}, \"option_1\": {\"description\": \"Option 1 for the poll question\", \"title\": \"Option 1\", \"type\": \"string\"}, \"option_2\": {\"description\": \"Option 2 for the poll question\", \"title\": \"Option 2\", \"type\": \"string\"}, \"option_3\": {\"description\": \"Option 3 for the poll question\", \"title\": \"Option 3\", \"type\": \"string\"}, \"option_4\": {\"description\": \"Option 4 for the poll question\", \"title\": \"Option 4\", \"type\": \"string\"}, \"option_5\": {\"description\": \"Option 5 for the poll question\", \"title\": \"Option 5\", \"type\": \"string\"}}, \"required\": [\"poll_question\", \"option_1\", \"option_2\", \"option_3\", \"option_4\", \"option_5\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"You are an AI assistant with extensive knowledge of politics, government systems, and how the world works. Your task is to generate engaging polls for news article readers that promote healthy discussion and critical thinking around political and current event topics.\n",
    "\n",
    "When generating a poll, keep the following guidelines in mind:\n",
    "\n",
    "1. Frame the poll question in a neutral and unbiased way, without leading the reader towards a particular answer or political ideology.\n",
    "2. Provide a range of reasonable answer options that represent different political perspectives and ideologies.\n",
    "3. Avoid using divisive or emotionally charged language that could inflame tensions or discourage open-minded discussion.\n",
    "4. Focus on substantive topics that are informative, relevant to the news article or current events, and have real-world political implications.\n",
    "5. Encourage readers to think critically, consider multiple viewpoints, and form their own opinions based on facts, evidence, and an understanding of how political systems and processes work.\n",
    "6. If appropriate, include an \"Other\" option with a free-response field to allow readers to provide their own perspectives.\n",
    "7. Draw upon your knowledge of political systems, institutions, and processes to provide context and nuance to the poll question and answer options.\n",
    "8. Aim to engage readers in thoughtful, respectful, and constructive dialogue that fosters a deeper understanding of political issues and encourages civic participation.\n",
    "\n",
    "\n",
    " Generate multiple choice poll question with 5 options for this story headline: {input}\n",
    " Follow the output formatting instructions: {format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(template=template_string)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt_template | model | output_parser\n",
    "result = chain.invoke({\"input\": top_5_content['story_headline'][2],\"format_instructions\": format_instructions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline story: I was forced to sell my home after HOA took $600 from my paycheck every two weeks over weeds – it was my only way out. See how lawmakers hope to crack down on overzealous HOAs\n",
      "{\n",
      "  \"poll_question\": \"What is your perspective on the proposed legislative measures for regulating Homeowners Associations (HOAs)?\",\n",
      "  \"option_1\": \"I fully support stronger regulations to protect homeowners from excessive HOA fees and penalties\",\n",
      "  \"option_2\": \"I believe that some regulation is necessary, but homeowners should also fulfill their responsibilities to the community\",\n",
      "  \"option_3\": \"I'm concerned that too much regulation could interfere with the ability of HOAs to maintain community standards and property values\",\n",
      "  \"option_4\": \"I don't think legislative intervention is necessary; disputes should be settled within the community or through legal recourse\",\n",
      "  \"option_5\": \"I have a different perspective or need more information to form an opinion\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('Headline story: ' + top_5_content['story_headline'][2])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"poll_question\": \"How should financial institutions handle potential fraudulent activity in an account?\",\n",
      "\"option_1\": \"The bank should immediately freeze all transactions and notify the account holder.\",\n",
      "\"option_2\": \"The bank should conduct its own investigation before making any changes to the account.\",\n",
      "\"option_3\": \"The bank should allow transactions to continue, but monitor the account closely for signs of further suspicious activity.\",\n",
      "\"option_4\": \"The bank should immediately return any funds withdrawn due to suspected fraud, even if this could potentially enable fraudulent activity.\",\n",
      "\"option_5\": \"Other (please specify)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Tool Calling Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `adding_function` with `{'input_1': 10, 'input_2': 10}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m20\u001b[0m\u001b[32;1m\u001b[1;3mIf you add ten to ten, you will get 20.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What will I get if I add ten to ten?',\n",
       " 'output': 'If you add ten to ten, you will get 20.'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent, tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ])\n",
    "model = ChatOpenAI(model=\"gpt-4\", api_key=api_key)\n",
    "\n",
    "@tool\n",
    "def adding_function(input_1: int, input_2: int) -> int:\n",
    "    \"\"\"Adds up the inputs\"\"\"\n",
    "    return input_1 + input_2\n",
    "\n",
    "tools = [adding_function]\n",
    "\n",
    "agent = create_tool_calling_agent(model, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": \"What will I get if I add ten to ten?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.pydantic_v1 import BaseModel\n",
    "from langchain.tools import tool\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")\n",
    "\n",
    "@tool(\"search-tool\", args_schema=SearchInput, return_direct=True)\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Look up things online.\"\"\"\n",
    "    return \"It is going to rain today.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search-tool\n",
      "search-tool(query: str) -> str - Look up things online.\n"
     ]
    }
   ],
   "source": [
    "print(search.name)\n",
    "print(search.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "def get_react_prompt_template():\n",
    "    # Get the react prompt template\n",
    "    return PromptTemplate.from_template(\"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def check_system_time(format: str = \"%Y-%m-%d %H:%M:%S\"):\n",
    "    \"\"\"Returns the current date and time in the specified format\"\"\"\n",
    "\n",
    "    # get the current date and time\n",
    "    current_time = datetime.datetime.now()\n",
    "    \n",
    "    # format the time as a string in the format \"YYYY-MM-DD HH:MM:SS\"\n",
    "    formatted_time = current_time.strftime(format)\n",
    "    \n",
    "    # return the formatted time\n",
    "    return formatted_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to check the current time to determine how much time is left until 5.\n",
      "Action: check_system_time\n",
      "Action Input: '%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[36;1m\u001b[1;3m'2024-05-20 12:26:08'\u001b[0m\u001b[32;1m\u001b[1;3mNow that I know the current time, I can calculate the time remaining until 5.\n",
      "Final Answer: You have approximately 4 hours and 34 minutes left until 5.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'I need to go on a run at 5. How much time do i have left?',\n",
       " 'output': 'You have approximately 4 hours and 34 minutes left until 5.'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "# Setup\n",
    "llm = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "# Get a react prompt template\n",
    "prompt_template = get_react_prompt_template() \n",
    "\n",
    "# set the tools\n",
    "tools = [check_system_time]\n",
    "\n",
    "# Construct the ReAct agent\n",
    "agent = create_react_agent(llm, tools, prompt_template)\n",
    "\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Get the current time\n",
    "agent_executor.invoke({\"input\": \"I need to go on a run at 5. How much time do i have left?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat History & Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run e35e809f-9821-4148-a11f-a0cd5eb92ea3 not found for run 4aee1da1-610e-4f5f-8ada-94e116423f85. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mIt seems like Shachi is just introducing herself. There's no question to answer.\n",
      "\n",
      "Final Answer: Hi Shachi! Nice to meet you.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"hi! I'm Shachi\",\n",
       " 'chat_history': [],\n",
       " 'output': 'Hi Shachi! Nice to meet you.'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "message_history = ChatMessageHistory()\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"hi! I'm Shachi\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
